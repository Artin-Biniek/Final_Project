input_filename,input_scenario,input_given,input_and,input_then,output_filename,output_scenario,output_given,output_and,output_then
Record1.rst,"Tag-Expressions v2\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 are based on :pypi:`cucumber-tag-expressions` with some extensions:\n\n* Tag-Expressions v2 provide `boolean logic expression`\n  (with ``and``, ``or`` and ``not`` operators and parenthesis for grouping expressions)\n* Tag-Expressions v2 are far more readable and composable than Tag-Expressions v1\n* Some boolean-logic-expressions where not possible with Tag-Expressions v1\n* Therefore, Tag-Expressions v2 supersedes the old-style tag-expressions.\n\n.. code-block:: gherkin\n    :caption: TAG-EXPRESSION EXAMPLES\n\n# -- EXAMPLE 1: Select features/scenarios that have the tags: @a and @b\n@a and @b\n\n# -- EXAMPLE 2: Select features/scenarios that have the tag: @a or @b\n@a or @b\n\n# -- EXAMPLE 3: Select features/scenarios that do not have the tag: @a\nnot @a\n\n# -- EXAMPLE 4: Select features/scenarios that have the tags: @a but not @b\n@a and not @b\n\n# -- EXAMPLE 5: Select features/scenarios that have the tags: (@a or @b) but not @c\n# HINT: Boolean expressions can be grouped with parenthesis.\n(@a or @b) and not @c","COMMAND-LINE EXAMPLE:\n\n.. code-block:: sh\n    :caption: USING: Tag-Expressions v2 with ``behave``\n\n    # -- SELECT-BY-TAG-EXPRESSION (with tag-expressions v2):\n    # Select all features / scenarios with both ""@foo"" and ""@bar"" tags.\n    $ behave --tags=""@foo and @bar"" features/\n\n    # -- EXAMPLE: Use default_tags from config-file ""behave.ini"".\n    # Use placeholder ""{config.tags}"" to refer to this tag-expression.\n    # HERE: config.tags = ""not (@xfail or @not_implemented)""\n    $ behave --tags=""(@foo or @bar) and {config.tags}"" --tags-help\n    ...\n    CURRENT TAG_EXPRESSION: ((foo or bar) and not (xfail or not_implemented))\n\n    # -- EXAMPLE: Uses Tag-Expression diagnostics with --tags-help option\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help --verbose\n\n.. seealso::\n\n    * https://docs.cucumber.io/cucumber/api/#tag-expressions\n    * :pypi:`cucumber-tag-expressions` (Python package)",,"Tag Matching with Tag-Expressions\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 support **partial string/tag matching** with wildcards.\nThis supports tag-expressions:\n\n=================== =========== =========== ===================================================\nTag Matching Idiom  Example 1   Example 2   Description\n=================== =========== =========== ===================================================\n``tag.starts_with`` ``@foo.*``  ``foo.*``   Search for tags that start with a ``prefix``.\n``tag.ends_with``   ``@*.one``  ``*.one``   Search for tags that end with a ``suffix``.\n``tag.contains``    ``@*foo*``  ``*foo*``   Search for tags that contain a ``part``.\n=================== =========== =========== ===================================================\n\n.. code-block:: gherkin\n    :caption: FILE: features/one.feature\n\n    Feature: Alice\n\n      @foo.one\n      Scenario: Alice.1\n        ...\n\n      @foo.two\n      Scenario: Alice.2\n        ...\n\n      @bar\n      Scenario: Alice.3\n        ...\n\nThe following command-line will select all features / scenarios with tags\nthat start with ""@foo."":\n\n.. code-block:: sh\n    :caption: USAGE EXAMPLE: Run behave with tag-matching expressions\n\n    $ behave -f plain --tags=""@foo.*"" features/one.feature\n    Feature: Alice\n\n      Scenario: Alice.1\n        ...\n\n      Scenario: Alice.2\n        ...\n\n    # -- HINT: Only Alice.1 and Alice.2 are matched (not: Alice.3).\n\n.. note::\n\n    * Filename matching wildcards are supported.\n      See :mod:`fnmatch` (Unix style filename matching).\n\n    * The tag matching functionality is an extension to :pypi:`cucumber-tag-expressions`.\n\n\nSelect the Tag-Expression Version to Use\n-------------------------------------------------------------------------------\n\nThe tag-expression version, that should be used by :pypi:`behave`,\ncan be specified in the :pypi:`behave` config-file.\n\nThis allows a user to select:\n\n* Tag-Expressions v1 (if needed)\n* Tag-Expressions v2 when it is feasible\n\nEXAMPLE:\n\n.. code-block:: ini\n    :caption: FILE: behave.ini\n\n    # SPECIFY WHICH TAG-EXPRESSION-PROTOCOL SHOULD BE USED:\n    #   SUPPORTED VALUES: v1, v2, auto_detect\n    #   CURRENT DEFAULT:  auto_detect\n    [behave]\n    tag_expression_protocol = v1    # -- Use Tag-Expressions v1.\n\n\nTag-Expressions v1\n-------------------------------------------------------------------------------\n\nTag-Expressions v1 are becoming deprecated (but are currently still supported).\nUse **Tag-Expressions v2** instead.\n\n.. note::\n\n    Tag-Expressions v1 support will be dropped in ``behave v1.4.0``",Feature1.feature,Select @foo, the tag expression @foo,,the tag expression selects elements with tags:\n        | tags         | selected? |\n        |              |   no      |\n        | @foo         |   yes     |\n        | @other       |   no      |\n        | @foo @other  |   yes     |
Record2.rst,"Tag-Expressions v2\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 are based on :pypi:`cucumber-tag-expressions` with some extensions:\n\n* Tag-Expressions v2 provide `boolean logic expression`\n  (with ``and``, ``or`` and ``not`` operators and parenthesis for grouping expressions)\n* Tag-Expressions v2 are far more readable and composable than Tag-Expressions v1\n* Some boolean-logic-expressions where not possible with Tag-Expressions v1\n* Therefore, Tag-Expressions v2 supersedes the old-style tag-expressions.\n\n.. code-block:: gherkin\n    :caption: TAG-EXPRESSION EXAMPLES\n\n# -- EXAMPLE 1: Select features/scenarios that have the tags: @a and @b\n@a and @b\n\n# -- EXAMPLE 2: Select features/scenarios that have the tag: @a or @b\n@a or @b\n\n# -- EXAMPLE 3: Select features/scenarios that do not have the tag: @a\nnot @a\n\n# -- EXAMPLE 4: Select features/scenarios that have the tags: @a but not @b\n@a and not @b\n\n# -- EXAMPLE 5: Select features/scenarios that have the tags: (@a or @b) but not @c\n# HINT: Boolean expressions can be grouped with parenthesis.\n(@a or @b) and not @c","COMMAND-LINE EXAMPLE:\n\n.. code-block:: sh\n    :caption: USING: Tag-Expressions v2 with ``behave``\n\n    # -- SELECT-BY-TAG-EXPRESSION (with tag-expressions v2):\n    # Select all features / scenarios with both ""@foo"" and ""@bar"" tags.\n    $ behave --tags=""@foo and @bar"" features/\n\n    # -- EXAMPLE: Use default_tags from config-file ""behave.ini"".\n    # Use placeholder ""{config.tags}"" to refer to this tag-expression.\n    # HERE: config.tags = ""not (@xfail or @not_implemented)""\n    $ behave --tags=""(@foo or @bar) and {config.tags}"" --tags-help\n    ...\n    CURRENT TAG_EXPRESSION: ((foo or bar) and not (xfail or not_implemented))\n\n    # -- EXAMPLE: Uses Tag-Expression diagnostics with --tags-help option\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help --verbose\n\n.. seealso::\n\n    * https://docs.cucumber.io/cucumber/api/#tag-expressions\n    * :pypi:`cucumber-tag-expressions` (Python package)",,"Tag Matching with Tag-Expressions\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 support **partial string/tag matching** with wildcards.\nThis supports tag-expressions:\n\n=================== =========== =========== ===================================================\nTag Matching Idiom  Example 1   Example 2   Description\n=================== =========== =========== ===================================================\n``tag.starts_with`` ``@foo.*``  ``foo.*``   Search for tags that start with a ``prefix``.\n``tag.ends_with``   ``@*.one``  ``*.one``   Search for tags that end with a ``suffix``.\n``tag.contains``    ``@*foo*``  ``*foo*``   Search for tags that contain a ``part``.\n=================== =========== =========== ===================================================\n\n.. code-block:: gherkin\n    :caption: FILE: features/one.feature\n\n    Feature: Alice\n\n      @foo.one\n      Scenario: Alice.1\n        ...\n\n      @foo.two\n      Scenario: Alice.2\n        ...\n\n      @bar\n      Scenario: Alice.3\n        ...\n\nThe following command-line will select all features / scenarios with tags\nthat start with ""@foo."":\n\n.. code-block:: sh\n    :caption: USAGE EXAMPLE: Run behave with tag-matching expressions\n\n    $ behave -f plain --tags=""@foo.*"" features/one.feature\n    Feature: Alice\n\n      Scenario: Alice.1\n        ...\n\n      Scenario: Alice.2\n        ...\n\n    # -- HINT: Only Alice.1 and Alice.2 are matched (not: Alice.3).\n\n.. note::\n\n    * Filename matching wildcards are supported.\n      See :mod:`fnmatch` (Unix style filename matching).\n\n    * The tag matching functionality is an extension to :pypi:`cucumber-tag-expressions`.\n\n\nSelect the Tag-Expression Version to Use\n-------------------------------------------------------------------------------\n\nThe tag-expression version, that should be used by :pypi:`behave`,\ncan be specified in the :pypi:`behave` config-file.\n\nThis allows a user to select:\n\n* Tag-Expressions v1 (if needed)\n* Tag-Expressions v2 when it is feasible\n\nEXAMPLE:\n\n.. code-block:: ini\n    :caption: FILE: behave.ini\n\n    # SPECIFY WHICH TAG-EXPRESSION-PROTOCOL SHOULD BE USED:\n    #   SUPPORTED VALUES: v1, v2, auto_detect\n    #   CURRENT DEFAULT:  auto_detect\n    [behave]\n    tag_expression_protocol = v1    # -- Use Tag-Expressions v1.\n\n\nTag-Expressions v1\n-------------------------------------------------------------------------------\n\nTag-Expressions v1 are becoming deprecated (but are currently still supported).\nUse **Tag-Expressions v2** instead.\n\n.. note::\n\n    Tag-Expressions v1 support will be dropped in ``behave v1.4.0``",Feature2.feature,Tag expression with 0..1 tags,the model elements with name and tags:\n        | name | tags         | Comment |\n        | S0   |              | Untagged    |\n        | S1   | @foo         | With 1 tag  |\n        | S2   | @other       |             |\n        | S3   | @foo @other  | With 2 tags |,note that are all combinations of 0..2 tags,"the tag expression selects model elements with: | tag expression | selected? | Case comment | | | S0, S1, S2, S3 | Select all (empty tag expression) | | @foo | S1, S3 | Select @foo | | not @foo | S0, S2 | not @foo, selects untagged elements | But note that tag expression variants are also supported"
Record3.rst,"Tag-Expressions v2\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 are based on :pypi:`cucumber-tag-expressions` with some extensions:\n\n* Tag-Expressions v2 provide `boolean logic expression`\n  (with ``and``, ``or`` and ``not`` operators and parenthesis for grouping expressions)\n* Tag-Expressions v2 are far more readable and composable than Tag-Expressions v1\n* Some boolean-logic-expressions where not possible with Tag-Expressions v1\n* Therefore, Tag-Expressions v2 supersedes the old-style tag-expressions.\n\n.. code-block:: gherkin\n    :caption: TAG-EXPRESSION EXAMPLES\n\n# -- EXAMPLE 1: Select features/scenarios that have the tags: @a and @b\n@a and @b\n\n# -- EXAMPLE 2: Select features/scenarios that have the tag: @a or @b\n@a or @b\n\n# -- EXAMPLE 3: Select features/scenarios that do not have the tag: @a\nnot @a\n\n# -- EXAMPLE 4: Select features/scenarios that have the tags: @a but not @b\n@a and not @b\n\n# -- EXAMPLE 5: Select features/scenarios that have the tags: (@a or @b) but not @c\n# HINT: Boolean expressions can be grouped with parenthesis.\n(@a or @b) and not @c","COMMAND-LINE EXAMPLE:\n\n.. code-block:: sh\n    :caption: USING: Tag-Expressions v2 with ``behave``\n\n    # -- SELECT-BY-TAG-EXPRESSION (with tag-expressions v2):\n    # Select all features / scenarios with both ""@foo"" and ""@bar"" tags.\n    $ behave --tags=""@foo and @bar"" features/\n\n    # -- EXAMPLE: Use default_tags from config-file ""behave.ini"".\n    # Use placeholder ""{config.tags}"" to refer to this tag-expression.\n    # HERE: config.tags = ""not (@xfail or @not_implemented)""\n    $ behave --tags=""(@foo or @bar) and {config.tags}"" --tags-help\n    ...\n    CURRENT TAG_EXPRESSION: ((foo or bar) and not (xfail or not_implemented))\n\n    # -- EXAMPLE: Uses Tag-Expression diagnostics with --tags-help option\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help --verbose\n\n.. seealso::\n\n    * https://docs.cucumber.io/cucumber/api/#tag-expressions\n    * :pypi:`cucumber-tag-expressions` (Python package)",,"Tag Matching with Tag-Expressions\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 support **partial string/tag matching** with wildcards.\nThis supports tag-expressions:\n\n=================== =========== =========== ===================================================\nTag Matching Idiom  Example 1   Example 2   Description\n=================== =========== =========== ===================================================\n``tag.starts_with`` ``@foo.*``  ``foo.*``   Search for tags that start with a ``prefix``.\n``tag.ends_with``   ``@*.one``  ``*.one``   Search for tags that end with a ``suffix``.\n``tag.contains``    ``@*foo*``  ``*foo*``   Search for tags that contain a ``part``.\n=================== =========== =========== ===================================================\n\n.. code-block:: gherkin\n    :caption: FILE: features/one.feature\n\n    Feature: Alice\n\n      @foo.one\n      Scenario: Alice.1\n        ...\n\n      @foo.two\n      Scenario: Alice.2\n        ...\n\n      @bar\n      Scenario: Alice.3\n        ...\n\nThe following command-line will select all features / scenarios with tags\nthat start with ""@foo."":\n\n.. code-block:: sh\n    :caption: USAGE EXAMPLE: Run behave with tag-matching expressions\n\n    $ behave -f plain --tags=""@foo.*"" features/one.feature\n    Feature: Alice\n\n      Scenario: Alice.1\n        ...\n\n      Scenario: Alice.2\n        ...\n\n    # -- HINT: Only Alice.1 and Alice.2 are matched (not: Alice.3).\n\n.. note::\n\n    * Filename matching wildcards are supported.\n      See :mod:`fnmatch` (Unix style filename matching).\n\n    * The tag matching functionality is an extension to :pypi:`cucumber-tag-expressions`.\n\n\nSelect the Tag-Expression Version to Use\n-------------------------------------------------------------------------------\n\nThe tag-expression version, that should be used by :pypi:`behave`,\ncan be specified in the :pypi:`behave` config-file.\n\nThis allows a user to select:\n\n* Tag-Expressions v1 (if needed)\n* Tag-Expressions v2 when it is feasible\n\nEXAMPLE:\n\n.. code-block:: ini\n    :caption: FILE: behave.ini\n\n    # SPECIFY WHICH TAG-EXPRESSION-PROTOCOL SHOULD BE USED:\n    #   SUPPORTED VALUES: v1, v2, auto_detect\n    #   CURRENT DEFAULT:  auto_detect\n    [behave]\n    tag_expression_protocol = v1    # -- Use Tag-Expressions v1.\n\n\nTag-Expressions v1\n-------------------------------------------------------------------------------\n\nTag-Expressions v1 are becoming deprecated (but are currently still supported).\nUse **Tag-Expressions v2** instead.\n\n.. note::\n\n    Tag-Expressions v1 support will be dropped in ``behave v1.4.0``",Featur3.feature,"Tag expression with two tags (@foo, @bar)",the model elements with name and tags: | name | tags | Comment | | S0 | | Untagged | | S1 | @foo | With 1 tag | | S2 | @bar | | | S3 | @other | | | S4 | @foo @bar | With 2 tags | | S5 | @foo @other | | | S6 | @bar @other | | | S7 | @foo @bar @other | With 3 tags |,note that are all combinations of 0..3 tags,"the tag expression selects model elements with: | tag expression | selected? | Case | | | S0, S1, S2, S3, S4, S5, S6, S7 | Select all | | @foo or @bar | S1, S2, S4, S5, S6, S7 | @foo or @bar | | @foo or not @bar | S0, S1, S3, S4, S5, S7 | @foo or not @bar | | not @foo or not @bar | S0, S1, S2, S3, S5, S6 | not @foo or @not @bar | | @foo and @bar | S4, S7 | @foo and @bar | | @foo and not @bar | S1, S5 | @foo and not @bar | | not @foo and not @bar | S0, S3 | not @foo and not @bar |"
Record4.rst,"Tag-Expressions v2\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 are based on :pypi:`cucumber-tag-expressions` with some extensions:\n\n* Tag-Expressions v2 provide `boolean logic expression`\n  (with ``and``, ``or`` and ``not`` operators and parenthesis for grouping expressions)\n* Tag-Expressions v2 are far more readable and composable than Tag-Expressions v1\n* Some boolean-logic-expressions where not possible with Tag-Expressions v1\n* Therefore, Tag-Expressions v2 supersedes the old-style tag-expressions.\n\n.. code-block:: gherkin\n    :caption: TAG-EXPRESSION EXAMPLES\n\n# -- EXAMPLE 1: Select features/scenarios that have the tags: @a and @b\n@a and @b\n\n# -- EXAMPLE 2: Select features/scenarios that have the tag: @a or @b\n@a or @b\n\n# -- EXAMPLE 3: Select features/scenarios that do not have the tag: @a\nnot @a\n\n# -- EXAMPLE 4: Select features/scenarios that have the tags: @a but not @b\n@a and not @b\n\n# -- EXAMPLE 5: Select features/scenarios that have the tags: (@a or @b) but not @c\n# HINT: Boolean expressions can be grouped with parenthesis.\n(@a or @b) and not @c","COMMAND-LINE EXAMPLE:\n\n.. code-block:: sh\n    :caption: USING: Tag-Expressions v2 with ``behave``\n\n    # -- SELECT-BY-TAG-EXPRESSION (with tag-expressions v2):\n    # Select all features / scenarios with both ""@foo"" and ""@bar"" tags.\n    $ behave --tags=""@foo and @bar"" features/\n\n    # -- EXAMPLE: Use default_tags from config-file ""behave.ini"".\n    # Use placeholder ""{config.tags}"" to refer to this tag-expression.\n    # HERE: config.tags = ""not (@xfail or @not_implemented)""\n    $ behave --tags=""(@foo or @bar) and {config.tags}"" --tags-help\n    ...\n    CURRENT TAG_EXPRESSION: ((foo or bar) and not (xfail or not_implemented))\n\n    # -- EXAMPLE: Uses Tag-Expression diagnostics with --tags-help option\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help\n    $ behave --tags=""(@foo and @bar) or @baz"" --tags-help --verbose\n\n.. seealso::\n\n    * https://docs.cucumber.io/cucumber/api/#tag-expressions\n    * :pypi:`cucumber-tag-expressions` (Python package)",,"Tag Matching with Tag-Expressions\n-------------------------------------------------------------------------------\n\nTag-Expressions v2 support **partial string/tag matching** with wildcards.\nThis supports tag-expressions:\n\n=================== =========== =========== ===================================================\nTag Matching Idiom  Example 1   Example 2   Description\n=================== =========== =========== ===================================================\n``tag.starts_with`` ``@foo.*``  ``foo.*``   Search for tags that start with a ``prefix``.\n``tag.ends_with``   ``@*.one``  ``*.one``   Search for tags that end with a ``suffix``.\n``tag.contains``    ``@*foo*``  ``*foo*``   Search for tags that contain a ``part``.\n=================== =========== =========== ===================================================\n\n.. code-block:: gherkin\n    :caption: FILE: features/one.feature\n\n    Feature: Alice\n\n      @foo.one\n      Scenario: Alice.1\n        ...\n\n      @foo.two\n      Scenario: Alice.2\n        ...\n\n      @bar\n      Scenario: Alice.3\n        ...\n\nThe following command-line will select all features / scenarios with tags\nthat start with ""@foo."":\n\n.. code-block:: sh\n    :caption: USAGE EXAMPLE: Run behave with tag-matching expressions\n\n    $ behave -f plain --tags=""@foo.*"" features/one.feature\n    Feature: Alice\n\n      Scenario: Alice.1\n        ...\n\n      Scenario: Alice.2\n        ...\n\n    # -- HINT: Only Alice.1 and Alice.2 are matched (not: Alice.3).\n\n.. note::\n\n    * Filename matching wildcards are supported.\n      See :mod:`fnmatch` (Unix style filename matching).\n\n    * The tag matching functionality is an extension to :pypi:`cucumber-tag-expressions`.\n\n\nSelect the Tag-Expression Version to Use\n-------------------------------------------------------------------------------\n\nThe tag-expression version, that should be used by :pypi:`behave`,\ncan be specified in the :pypi:`behave` config-file.\n\nThis allows a user to select:\n\n* Tag-Expressions v1 (if needed)\n* Tag-Expressions v2 when it is feasible\n\nEXAMPLE:\n\n.. code-block:: ini\n    :caption: FILE: behave.ini\n\n    # SPECIFY WHICH TAG-EXPRESSION-PROTOCOL SHOULD BE USED:\n    #   SUPPORTED VALUES: v1, v2, auto_detect\n    #   CURRENT DEFAULT:  auto_detect\n    [behave]\n    tag_expression_protocol = v1    # -- Use Tag-Expressions v1.\n\n\nTag-Expressions v1\n-------------------------------------------------------------------------------\n\nTag-Expressions v1 are becoming deprecated (but are currently still supported).\nUse **Tag-Expressions v2** instead.\n\n.. note::\n\n    Tag-Expressions v1 support will be dropped in ``behave v1.4.0``",Featue4.feature,"Tag expression with three tags (@foo, @bar, @zap)",the model elements with name and tags: | name | tags | Comment | | S0 | | Untagged | | S1 | @foo | With 1 tag | | S2 | @bar | | | S3 | @zap | | | S4 | @other | | | S5 | @foo @bar | With 2 tags | | S6 | @foo @zap | | | S7 | @foo @other | | | S8 | @bar @zap | | | S9 | @bar @other | | | S10 | @zap @other | | | S11 | @foo @bar @zap | With 3 tags | | S12 | @foo @bar @other | | | S13 | @foo @zap @other | | | S14 | @bar @zap @other | | | S15 | @foo @bar @zap @other | With 4 tags |,note that are all combinations of 0..4 tags,"the tag expression selects model elements with: | tag expression | selected? | Case | | (@foo or @bar) and @zap | S6, S8, S11, S13, S14, S15 | (@foo or @bar) and @zap | | (@foo or @bar) and not @zap | S1, S2, S5, S7, S9, S12 | (@foo or @bar) and not @zap | | (@foo or not @bar) and @zap | S3, S6, S10, S11, S13, S15 | (@foo or not @bar) and @zap |"
Record5.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature5.feature,Feature Setup,a new working directory,an empty file named features/environment.py,
Record6.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature6.feature,Use fixture with generator-function (setup/cleanup),"a file named features/environment.py with: from __future__ import print_function from behave.fixture import fixture, use_fixture @fixture(name=browser.firefox) def browser_firefox(context): print(FIXTURE-SETUP: browser.firefox) context.browser = firefox yield print(FIXTURE-CLEANUP: browser.firefox) # -- SCOPE-CLEANUP OR EXPLICIT: del context.browser def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context) ",a file named features/alice.feature,"it should pass with  2 scenarios passed, 0 failed, 0 skipped 2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record7.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature7.feature,Use fixture with function (setup-only),a file named features/environment.py,a file named features/bob.feature,"it should pass with  2 scenarios passed, 0 failed, 0 skipped and 2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record8.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature8.feature,Use fixture (case: feature), a file named features/environment.py,a file namedfeatures/use2.feature," it should pass with  1 feature passed, 0 failed, 0 skipped  2 scenarios passed, 0 failed, 0 skipped 2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record9.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature9.feature,Use fixture (case: step),a file named features/environment.py,an empty file named behave4me/__init__.py,"it should pass with  2 scenarios passed, 0 failed, 0 skipped 3 steps passed, 0 failed, 0 skipped, 0 undefined"
Record10.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature10.feature,Use multiple fixtures (with setup/cleanup),a file named features/environment.py,a file named features/two.feature,"it should pass with 2 scenarios passed, 0 failed, 0 skipped   2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record11.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature11.feature,Use same fixture twice with different args, a file named features/environment.py,a file named features/two.feature,"it should pass with 2 scenarios passed, 0 failed, 0 skipped  2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record12.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature12.feature, Use invalid fixture (with two yields or more),a file named features/environment.py,a file named features/invalid_fixture.feature,"it should fail with 1 scenario passed, 1 failed, 0 skipped  2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record13.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature13.feature,Fixture with cleanup-error causes failed (case: scenario),a file named features/environment.py,a file named features/bad_fixture.feature," it should fail with  1 scenario passed, 1 failed, 0 skipped  2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record14.rst,".. _docid.fixtures: Fixtures ============================================================================== A common task during test execution is to: * setup a functionality when a test-scope is entered * cleanup (or teardown) the functionality at the end of the test-scope **Fixtures** are provided as concept to simplify this setup/cleanup task in `behave`_. .. include:: _common_extlinks.rst Providing a Fixture ------------------- .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or in: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser # -- FIXTURE-VARIANT 1: Use generator-function @fixture def browser_firefox(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: context.browser = FirefoxBrowser(timeout, **kwargs) yield context.browser # -- CLEANUP-FIXTURE PART: context.browser.shutdown() .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): # -- SETUP-FIXTURE PART: And register as context-cleanup task. browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) return browser # -- CLEANUP-FIXTURE PART: browser.shutdown() # Fixture-cleanup is called when current context-layer is removed. .. seealso:: A *fixture* is similar to: * a :func:`contextlib.contextmanager` * a `pytest.fixture`_ * the `scope guard`_ idiom","Using a Fixture --------------- In many cases, the usage of a fixture is triggered by the ``fixture-tag`` in a feature file. The ``fixture-tag`` marks that a fixture should be used in this scenario/feature (as test-scope). .. code-block:: gherkin # -- FILE: features/use_fixture1.feature Feature: Use Fixture on Scenario Level @fixture.browser.firefox Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web  -- AFTER-SCENARIO: Cleanup fixture.browser.firefox .. code-block:: gherkin # -- FILE: features/use_fixture2.feature @fixture.browser.firefox Feature: Use Fixture on Feature Level Scenario: Use Web Browser Firefox Given I load web page https://somewhere.web ... Scenario: Another Browser Test ...  -- AFTER-FEATURE: Cleanup fixture.browser.firefox A **fixture** can be used by calling the :func:`~behave.use_fixture()` function. The :func:`~behave.use_fixture()` call performs the ``SETUP-FIXTURE`` part and returns the setup result. In addition, it ensures that ``CLEANUP-FIXTURE`` part is called later-on when the current context-layer is removed. Therefore, any manual cleanup handling in the ``after_tag()`` hook is not necessary. .. code-block:: python # -- FILE: features/environment.py from behave import use_fixture from behave4my_project.fixtures import browser_firefox def before_tag(context, tag): if tag == fixture.browser.firefox: use_fixture(browser_firefox, context, timeout=10)",,"Realistic Example ~~~~~~~~~~~~~~~~~ A more realistic example by using a fixture registry is shown below: .. code-block:: python # -- FILE: features/environment.py from behave.fixture import use_fixture_by_tag, fixture_call_params from behave4my_project.fixtures import browser_firefox, browser_chrome # -- REGISTRY DATA SCHEMA 1: fixture_func fixture_registry1 = { fixture.browser.firefox: browser_firefox, fixture.browser.chrome: browser_chrome, } # -- REGISTRY DATA SCHEMA 2: (fixture_func, fixture_args, fixture_kwargs) fixture_registry2 = { fixture.browser.firefox: fixture_call_params(browser_firefox), fixture.browser.chrome: fixture_call_params(browser_chrome, timeout=12), } def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry1): # -- MORE: Tag processing steps ... .. code-block:: python # -- FILE: behave/fixture.py # ... def use_fixture_by_tag(tag, context, fixture_registry): fixture_data = fixture_registry.get(tag, None) if fixture_data is None: raise LookupError(Unknown fixture-tag: %s % tag) # -- FOR DATA SCHEMA 1: fixture_func = fixture_data return use_fixture(fixture_func, context) # -- FOR DATA SCHEMA 2: fixture_func, fixture_args, fixture_kwargs = fixture_data return use_fixture(fixture_func, context, *fixture_args, **fixture_kwargs) .. hint:: **Naming Convention for Fixture Tags** Fixture tags should start with ``@fixture.*`` prefix to improve readability and understandibilty in feature files (Gherkin). Tags are used for different purposes. Therefore, it should be clear when a ``fixture-tag`` is used. Fixture Cleanup Points ------------------------------------------------------------------------------ The point when a fixture-cleanup is performed depends on the scope where :func:`~behave.use_fixture()` is called (and the fixture-setup is performed). ============= =========================== ========================================================================================== Context Layer Fixture-Setup Point Fixture-Cleanup Point ============= =========================== ========================================================================================== test run In ``before_all()`` hook After ``after_all()`` at end of test-run. feature In ``before_feature()`` After ``after_feature()``, at end of feature. feature In ``before_tag()`` After ``after_feature()`` for feature tag. scenario In ``before_scenario()`` After ``after_scenario()``, at end of scenario. scenario In ``before_tag()`` After ``after_scenario()`` for scenario tag. scenario In a step After ``after_scenario()``. Fixture is usable until end of scenario. ============= =========================== ========================================================================================== Fixture Setup/Cleanup Semantics ------------------------------------------------------------------------------ If an error occurs during fixture-setup (meaning an exception is raised): * Feature/scenario execution is aborted * Any remaining fixture-setups are skipped * After feature/scenario hooks are processed * All fixture-cleanups and context cleanups are performed * The feature/scenario is marked as failed If an error occurs during fixture-cleanup (meaning an exception is raised): * All remaining fixture-cleanups and context cleanups are performed * First cleanup-error is reraised to pass failure to user (test runner) * The feature/scenario is marked as failed Ensure Fixture Cleanups with Fixture Setup Errors ------------------------------------------------------------------------------ Fixture-setup errors are special because a cleanup of a fixture is in many cases not necessary (or rather difficult because the fixture object is only partly created, etc.). Therefore, if an error occurs during fixture-setup (meaning: an exception is raised), the fixture-cleanup part is normally not called. If you need to ensure that the fixture-cleanup is performed, you need to provide a slightly different fixture implementation: .. code-block:: python # -- FILE: behave4my_project/fixtures.py (or: features/environment.py) from behave import fixture from somewhere.browser.firefox import FirefoxBrowser def setup_fixture_part2_with_error(arg): raise RuntimeError(OOPS-FIXTURE-SETUP-ERROR-HERE) # -- FIXTURE-VARIANT 1: Use generator-function with try/finally. @fixture def browser_firefox(context, timeout=30, **kwargs): try: browser = FirefoxBrowser(timeout, **kwargs) browser.part2 = setup_fixture_part2_with_error(OOPS) context.browser = browser # NOT_REACHED yield browser # -- NORMAL FIXTURE-CLEANUP PART: NOT_REACHED due to setup-error. finally: browser.shutdown() # -- CLEANUP: When generator-function is left. .. code-block:: python # -- FIXTURE-VARIANT 2: Use normal function and register cleanup-task early. from somewhere.browser.chrome import ChromeBrowser @fixture def browser_chrome(context, timeout=30, **kwargs): browser = ChromeBrowser(timeout, **kwargs) context.browser = browser context.add_cleanup(browser.shutdown) # -- ENSURE-CLEANUP EARLY browser.part2 = setup_fixture_part2_with_error(OOPS) return browser # NOT_REACHED # -- CLEANUP: browser.shutdown() when context-layer is removed. .. note:: An fixture-setup-error that occurs when the browser object is created, is not covered by these solutions and not so easy to solve. Composite Fixtures ------------------------------------------------------------------------------ The last section already describes some problems when you use complex or *composite fixtures*. It must be ensured that cleanup of already created fixture parts is performed even when errors occur late in the creation of a *composite fixture*. This is basically a `scope guard`_ problem. Solution 1: ~~~~~~~~~~~ .. code-block:: python # -- FILE: behave4my_project/fixtures.py # SOLUTION 1: Use use_fixture() to ensure cleanup even in case of errors. from behave import fixture, use_fixture @fixture def foo(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. @fixture def bar(context, *args, **kwargs): pass # -- FIXTURE IMPLEMENTATION: Not of interest here. # -- SOLUTION: With use_fixture() # ENSURES: foo-fixture is cleaned up even when setup-error occurs later. @fixture def composite1(context, *args, **kwargs): the_fixture1 = use_fixture(foo, context) the_fixture2 = use_fixture(bar, context) return [the_fixture1, the_fixture2] Solution 2: ~~~~~~~~~~~ .. code-block:: python # -- ALTERNATIVE SOLUTION: With use_composite_fixture_with() from behave import fixture from behave.fixture import use_composite_fixture_with, fixture_call_params @fixture def composite2(context, *args, **kwargs): the_composite = use_composite_fixture_with(context, [ fixture_call_params(foo, name=foo), fixture_call_params(bar, name=bar), ]) return the_composite",Feature14.feature,Multiple fixture cleanup-errors cause no abort after first error (case: scenario),a file named features/environment.py, a file named features/bad_fixture2.feature,"it should fail with 1 scenario passed, 1 failed, 0 skipped 2 steps passed, 0 failed, 0 skipped, 0 undefined"
Record15.rst,EXAMPLE: Use Environment Variables in Steps ============================================================================= :RELATED TO: `issue #497`_ This directory provides a simple example how you can use environment variables in step implementations.,# -- USE: -f plain --no-capture (via behave.ini defaults),,When I use the environment variable $LOGNAME ... passed,Feature15.feature,Test Environment variable concept,,,
Record16.rst,"EXAMPLE: Disable Background Inheritance Mechanism for Scenario =============================================================================== :RELATED-TO: #756 This example shows how the Background inheritance mechanism in Gherkin can be disabled in ``behave``. Parts of the recipe: * features/example.feature (Feature file as example) * features/environment.py (glue code and hooks for fixture-tag / fixture) * behave_fixture_lib/no_background.py (fixture implementation, workhorse) .. warning:: BEWARE: This shows you how can do it, not that you should do it BETTER: * Use Rules to group Scenarios, each with its own Background (in Gherkin v6) * Split Feature aspects into multiple feature files (if needed) * ... (see issue #756 above)",Explanation ------------------------------------------------------------------------ Example code how to provide a behave fixture to disable the background inheritance mechanism by using a fixture / fixture-tag. The fixture-tag @fixture.behave.no_background marks the location in Gherkin (which Scenario) where the fixture should be used,,"he environment file provides the glue code that the fixture is called: .. code-block:: python # -- FILE: features/environment.py from behave_fixture_lib.no_background import behave_no_background from behave.fixture import use_fixture_by_tag # -- FIXTURE REGISTRY: fixture_registry = { fixture.behave.no_background: behave_no_background, } # ----------------------------------------------------------------------------- # HOOKS: # ----------------------------------------------------------------------------- def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry) .. code-block:: python # -- FILE: behave_fixture_lib/no_background.py (fixture implementation) from behave import fixture @fixture(name=fixture.behave.no_background) def behave_no_background(ctx): # -- SETUP-PART-ONLY: Disable background inheritance (for scenarios only). current_scenario = ctx.scenario if current_scenario: print(FIXTURE-HINT: DISABLE-BACKGROUND FOR: %s % current_scenario.name) current_scenario.use_background = False",Feature16.feature,Alice,, note that BACKGROUND STEPS are executed here,
Record17.rst,"EXAMPLE: Disable Background Inheritance Mechanism for Scenario =============================================================================== :RELATED-TO: #756 This example shows how the Background inheritance mechanism in Gherkin can be disabled in ``behave``. Parts of the recipe: * features/example.feature (Feature file as example) * features/environment.py (glue code and hooks for fixture-tag / fixture) * behave_fixture_lib/no_background.py (fixture implementation, workhorse) .. warning:: BEWARE: This shows you how can do it, not that you should do it BETTER: * Use Rules to group Scenarios, each with its own Background (in Gherkin v6) * Split Feature aspects into multiple feature files (if needed) * ... (see issue #756 above)",Explanation ------------------------------------------------------------------------ Example code how to provide a behave fixture to disable the background inheritance mechanism by using a fixture / fixture-tag. The fixture-tag @fixture.behave.no_background marks the location in Gherkin (which Scenario) where the fixture should be used,,"he environment file provides the glue code that the fixture is called: .. code-block:: python # -- FILE: features/environment.py from behave_fixture_lib.no_background import behave_no_background from behave.fixture import use_fixture_by_tag # -- FIXTURE REGISTRY: fixture_registry = { fixture.behave.no_background: behave_no_background, } # ----------------------------------------------------------------------------- # HOOKS: # ----------------------------------------------------------------------------- def before_tag(context, tag): if tag.startswith(fixture.): return use_fixture_by_tag(tag, context, fixture_registry) .. code-block:: python # -- FILE: behave_fixture_lib/no_background.py (fixture implementation) from behave import fixture @fixture(name=fixture.behave.no_background) def behave_no_background(ctx): # -- SETUP-PART-ONLY: Disable background inheritance (for scenarios only). current_scenario = ctx.scenario if current_scenario: print(FIXTURE-HINT: DISABLE-BACKGROUND FOR: %s % current_scenario.name) current_scenario.use_background = False",Feature17.feature,Bob,I need another scenario setup,note that NO-BACKGROUND STEPS are executed here,
Record18.rst,"EXAMPLE: Use Soft Assertions in behave ============================================================================= :RELATED TO: `discussion #1094`_ This directory provides a simple example how soft-assertions can be used in ``behave`` by using the ``assertpy`` package. HINT: * Python2.7: @soft_assertions() decorator does not seem to work. Use ContextManager solution instead, like: ``with soft_assertions(): ...``",":Bootstrap ----------------------------------------------------------------------------- ASSUMPTIONS: * Python3 is installed (or: Python2.7) * virtualenv is installed (otherwise use: pip install virtualenv) Create a virtual-environment with virtualenv and activate it:: $ python3 -mvirtualenv .venv # -- STEP 2: Activate the virtualenv # CASE 1: BASH-LIKE SHELL (on UNIX-like platform: Linux, macOS, WSL, ...) $ source .venv/bin/activate # CASE 2: CMD SHELL (on Windows) cmd> .venv/Scripts/activate Install the required Python packages in the virtualenv:: $ pip install -r py.requirements.txt ",,"Run the Example ----------------------------------------------------------------------------- :: # -- USE: -f plain --no-capture (via behave.ini defaults) $ ../../bin/behave -f pretty features Feature: Use Soft Assertions in behave # features/soft_asserts.feature:1 RELATED TO: https://github.com/behave/behave/discussions/1094 Scenario: Failing with Soft Assertions -- CASE 1 # features/soft_asserts.feature:5 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the numbers 2 and 12 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <2> to be greater than or equal to <5>, but was not. But note that the step-2 (then step) is expected to fail # None @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 2 # features/soft_asserts.feature:17 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 4 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 1 and CASE 2 # features/soft_asserts.feature:28 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 2 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <2> to be greater than or equal to <5>, but was not. And the numbers 3 and 4 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <3> to be greater than or equal to <5>, but was not. 2. Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 Scenario: Passing # features/soft_asserts.feature:37 Given a step passes # ../../behave4cmd0/passing_steps.py:23 And note that this scenario should be executed and should pass # ../../behave4cmd0/note_steps.py:15 Failing scenarios: features/soft_asserts.feature:5 Failing with Soft Assertions -- CASE 1 features/soft_asserts.feature:17 Failing with Soft Assertions -- CASE 2 features/soft_asserts.feature:28 Failing with Soft Assertions -- CASE 1 and CASE 2 0 features passed, 1 failed, 0 skipped 1 scenario passed, 3 failed, 0 skipped 11 steps passed, 4 failed, 1 skipped, 0 undefined",Feature18.feature,Failing with Soft Assertions -- CASE 1s,a minimum number value of 5,,the numbers 2 and 12 are in the valid range But note that the step-2 (then step) is expected to fail
Record19.rst,"EXAMPLE: Use Soft Assertions in behave ============================================================================= :RELATED TO: `discussion #1094`_ This directory provides a simple example how soft-assertions can be used in ``behave`` by using the ``assertpy`` package. HINT: * Python2.7: @soft_assertions() decorator does not seem to work. Use ContextManager solution instead, like: ``with soft_assertions(): ...``",":Bootstrap ----------------------------------------------------------------------------- ASSUMPTIONS: * Python3 is installed (or: Python2.7) * virtualenv is installed (otherwise use: pip install virtualenv) Create a virtual-environment with virtualenv and activate it:: $ python3 -mvirtualenv .venv # -- STEP 2: Activate the virtualenv # CASE 1: BASH-LIKE SHELL (on UNIX-like platform: Linux, macOS, WSL, ...) $ source .venv/bin/activate # CASE 2: CMD SHELL (on Windows) cmd> .venv/Scripts/activate Install the required Python packages in the virtualenv:: $ pip install -r py.requirements.txt ",,"Run the Example ----------------------------------------------------------------------------- :: # -- USE: -f plain --no-capture (via behave.ini defaults) $ ../../bin/behave -f pretty features Feature: Use Soft Assertions in behave # features/soft_asserts.feature:1 RELATED TO: https://github.com/behave/behave/discussions/1094 Scenario: Failing with Soft Assertions -- CASE 1 # features/soft_asserts.feature:5 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the numbers 2 and 12 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <2> to be greater than or equal to <5>, but was not. But note that the step-2 (then step) is expected to fail # None @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 2 # features/soft_asserts.feature:17 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 4 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 1 and CASE 2 # features/soft_asserts.feature:28 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 2 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <2> to be greater than or equal to <5>, but was not. And the numbers 3 and 4 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <3> to be greater than or equal to <5>, but was not. 2. Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 Scenario: Passing # features/soft_asserts.feature:37 Given a step passes # ../../behave4cmd0/passing_steps.py:23 And note that this scenario should be executed and should pass # ../../behave4cmd0/note_steps.py:15 Failing scenarios: features/soft_asserts.feature:5 Failing with Soft Assertions -- CASE 1 features/soft_asserts.feature:17 Failing with Soft Assertions -- CASE 2 features/soft_asserts.feature:28 Failing with Soft Assertions -- CASE 1 and CASE 2 0 features passed, 1 failed, 0 skipped 1 scenario passed, 3 failed, 0 skipped 11 steps passed, 4 failed, 1 skipped, 0 undefined",Feature19.feature,Failing with Soft Assertions -- CASE 2,a minimum number value of 5,the number 8 is in the valid range,the number 4 is in the valid range
Record20.rst,"EXAMPLE: Use Soft Assertions in behave ============================================================================= :RELATED TO: `discussion #1094`_ This directory provides a simple example how soft-assertions can be used in ``behave`` by using the ``assertpy`` package. HINT: * Python2.7: @soft_assertions() decorator does not seem to work. Use ContextManager solution instead, like: ``with soft_assertions(): ...``",":Bootstrap ----------------------------------------------------------------------------- ASSUMPTIONS: * Python3 is installed (or: Python2.7) * virtualenv is installed (otherwise use: pip install virtualenv) Create a virtual-environment with virtualenv and activate it:: $ python3 -mvirtualenv .venv # -- STEP 2: Activate the virtualenv # CASE 1: BASH-LIKE SHELL (on UNIX-like platform: Linux, macOS, WSL, ...) $ source .venv/bin/activate # CASE 2: CMD SHELL (on Windows) cmd> .venv/Scripts/activate Install the required Python packages in the virtualenv:: $ pip install -r py.requirements.txt ",,"Run the Example ----------------------------------------------------------------------------- :: # -- USE: -f plain --no-capture (via behave.ini defaults) $ ../../bin/behave -f pretty features Feature: Use Soft Assertions in behave # features/soft_asserts.feature:1 RELATED TO: https://github.com/behave/behave/discussions/1094 Scenario: Failing with Soft Assertions -- CASE 1 # features/soft_asserts.feature:5 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the numbers 2 and 12 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <2> to be greater than or equal to <5>, but was not. But note that the step-2 (then step) is expected to fail # None @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 2 # features/soft_asserts.feature:17 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 4 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 1 and CASE 2 # features/soft_asserts.feature:28 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 2 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <2> to be greater than or equal to <5>, but was not. And the numbers 3 and 4 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <3> to be greater than or equal to <5>, but was not. 2. Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 Scenario: Passing # features/soft_asserts.feature:37 Given a step passes # ../../behave4cmd0/passing_steps.py:23 And note that this scenario should be executed and should pass # ../../behave4cmd0/note_steps.py:15 Failing scenarios: features/soft_asserts.feature:5 Failing with Soft Assertions -- CASE 1 features/soft_asserts.feature:17 Failing with Soft Assertions -- CASE 2 features/soft_asserts.feature:28 Failing with Soft Assertions -- CASE 1 and CASE 2 0 features passed, 1 failed, 0 skipped 1 scenario passed, 3 failed, 0 skipped 11 steps passed, 4 failed, 1 skipped, 0 undefined",Feature20.feature,Failing with Soft Assertions -- CASE 1 and CASE 2, a minimum number value of 5,the numbers 3 and 4 are in the valid range, the number 2 is in the valid range
Record21.rst,"EXAMPLE: Use Soft Assertions in behave ============================================================================= :RELATED TO: `discussion #1094`_ This directory provides a simple example how soft-assertions can be used in ``behave`` by using the ``assertpy`` package. HINT: * Python2.7: @soft_assertions() decorator does not seem to work. Use ContextManager solution instead, like: ``with soft_assertions(): ...``",":Bootstrap ----------------------------------------------------------------------------- ASSUMPTIONS: * Python3 is installed (or: Python2.7) * virtualenv is installed (otherwise use: pip install virtualenv) Create a virtual-environment with virtualenv and activate it:: $ python3 -mvirtualenv .venv # -- STEP 2: Activate the virtualenv # CASE 1: BASH-LIKE SHELL (on UNIX-like platform: Linux, macOS, WSL, ...) $ source .venv/bin/activate # CASE 2: CMD SHELL (on Windows) cmd> .venv/Scripts/activate Install the required Python packages in the virtualenv:: $ pip install -r py.requirements.txt ",,"Run the Example ----------------------------------------------------------------------------- :: # -- USE: -f plain --no-capture (via behave.ini defaults) $ ../../bin/behave -f pretty features Feature: Use Soft Assertions in behave # features/soft_asserts.feature:1 RELATED TO: https://github.com/behave/behave/discussions/1094 Scenario: Failing with Soft Assertions -- CASE 1 # features/soft_asserts.feature:5 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the numbers 2 and 12 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <2> to be greater than or equal to <5>, but was not. But note that the step-2 (then step) is expected to fail # None @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 2 # features/soft_asserts.feature:17 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 4 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 @behave.continue_after_failed_step Scenario: Failing with Soft Assertions -- CASE 1 and CASE 2 # features/soft_asserts.feature:28 Given a minimum number value of 5 # features/steps/number_steps.py:16 Then the number 2 is in the valid range # features/steps/number_steps.py:21 Assertion Failed: Expected <2> to be greater than or equal to <5>, but was not. And the numbers 3 and 4 are in the valid range # features/steps/number_steps.py:27 Assertion Failed: soft assertion failures: 1. Expected <3> to be greater than or equal to <5>, but was not. 2. Expected <4> to be greater than or equal to <5>, but was not. And the number 8 is in the valid range # features/steps/number_steps.py:21 But note that the step-2 and step-3 are expected to fail # ../../behave4cmd0/note_steps.py:15 But note that the step-4 should pass # ../../behave4cmd0/note_steps.py:15 Scenario: Passing # features/soft_asserts.feature:37 Given a step passes # ../../behave4cmd0/passing_steps.py:23 And note that this scenario should be executed and should pass # ../../behave4cmd0/note_steps.py:15 Failing scenarios: features/soft_asserts.feature:5 Failing with Soft Assertions -- CASE 1 features/soft_asserts.feature:17 Failing with Soft Assertions -- CASE 2 features/soft_asserts.feature:28 Failing with Soft Assertions -- CASE 1 and CASE 2 0 features passed, 1 failed, 0 skipped 1 scenario passed, 3 failed, 0 skipped 11 steps passed, 4 failed, 1 skipped, 0 undefined",Feature21.feature,Passing,a step passes,,note that this scenario should be executed and should pass
Record22.rst,".. _tutorial: ======== Tutorial ======== First, :doc:`install behave <install>`. Now make a directory called features. In that directory create a file called tutorial.feature containing: .. code-block:: gherkin Feature: showing off behave Scenario: run a simple test Given we have behave installed When we implement a test Then behave will test it for us! Make a new directory called features/steps. In that directory create a file called tutorial.py containing: .. code-block:: python from behave import * @given('we have behave installed') def step_impl(context): pass @when('we implement a test') def step_impl(context): assert True is not False @then('behave will test it for us!') def step_impl(context): assert context.failed is False","% behave Feature: showing off behave # features/tutorial.feature:1 Scenario: run a simple test # features/tutorial.feature:3 Given we have behave installed # features/steps/tutorial.py:3 When we implement a test # features/steps/tutorial.py:7 Then behave will test it for us! # features/steps/tutorial.py:11 1 feature passed, 0 failed, 0 skipped 1 scenario passed, 0 failed, 0 skipped 3 steps passed, 0 failed, 0 skipped, 0 undefined Now, continue reading to learn how to make the most of *behave*. Features ======== *behave* operates on directories containing: 1. `feature files`_ written by your Business Analyst / Sponsor / whoever with your behaviour scenarios in it, and 2. a steps directory with `Python step implementations`_ for the scenarios. You may optionally include some `environmental controls`_ (code to run before and after steps, scenarios, features or the whole shooting match). The minimum requirement for a features directory is:: features/ features/everything.feature features/steps/ features/steps/steps.py A more complex directory might look like:: features/ features/signup.feature features/login.feature features/account_details.feature features/environment.py features/steps/ features/steps/website.py features/steps/utils.py If you're having trouble setting things up and want to see what *behave* is doing in attempting to find your features use the -v (verbose) command-line switch.",,"Sometimes a scenario should be run with a number of variables giving a set of known states, actions to take and expected outcomes, all using the same basic actions. You may use a Scenario Outline to achieve this:",Feature22.feature,run a simple test,we have behave installed,,behave will test it for us!
Record23.rst,.. _id.appendix.formatters: ======================== Formatters and Reporters ======================== :pypi:`behave` provides 2 different concepts for reporting results of a test run: * formatters * reporters A slightly different interface is provided for each formatter concept. The ``Formatter`` is informed about each step that is taken. The ``Reporter`` has a more coarse-grained API. Reporters --------- The following reporters are currently supported: ============== ================================================================ Name Description ============== ================================================================ junit Provides JUnit XML-like output. summary Provides a summary of the test run. ============== ================================================================ Formatters ---------- The following formatters are currently supported: ============== ======== ================================================================ Name Mode Description ============== ======== ================================================================ help normal Shows all registered formatters. bad_steps dry-run Shows BAD STEP-DEFINITIONS (if any exist). json normal JSON dump of test run json.pretty normal JSON dump of test run (human readable) plain normal Very basic formatter with maximum compatibility pretty normal Standard colourised pretty formatter progress normal Shows dotted progress for each executed scenario. progress2 normal Shows dotted progress for each executed step. progress3 normal Shows detailed progress for each step of a scenario. rerun normal Emits scenario file locations of failing scenarios sphinx.steps dry-run Generate sphinx-based documentation for step definitions. steps dry-run Shows step definitions (step implementations). steps.catalog dry-run Shows non-technical documentation for step definitions. steps.code dry-run Shows executed steps combined with their code. steps.doc dry-run Shows documentation for step definitions. steps.usage dry-run Shows how step definitions are used by steps (in feature files). tags dry-run Shows tags (and how often they are used). tags.location dry-run Shows tags and the location where they are used. ============== ======== ================================================================ .. note:: You can use more than one formatter during a test run. But in general you have only one formatter that writes to ``stdout``. The Mode column indicates if a formatter is intended to be used in dry-run (``--dry-run`` command-line option) or normal mode.,"User-Defined Formatters ----------------------- Behave allows you to provide your own formatter (class):: # -- USE: Formatter class Json2Formatter in python module foo.bar # NOTE: Formatter must be importable from python search path. behave -f foo.bar:Json2Formatter ... The usage of a user-defined formatter can be simplified by providing an alias name for it in the configuration file: .. code-block:: ini # -- FILE: behave.ini # ALIAS SUPPORTS: behave -f json2 ... # NOTE: Formatter aliases may override builtin formatters. [behave.formatters] json2 = foo.bar:Json2Formatter If your formatter can be configured, you should use the userdata concept to provide them. The formatter should use the attribute schema: .. code-block:: ini # -- FILE: behave.ini # SCHEMA: behave.formatter.<FORMATTER_NAME>.<ATTRIBUTE_NAME> [behave.userdata] behave.formatter.json2.use_pretty = true # -- SUPPORTS ALSO: # behave -f json2 -D behave.formatter.json2.use_pretty ... More Formatters --------------- The following contributed formatters are currently known: ============== ========================================================================= Name Description ============== ========================================================================= allure :pypi:`allure-behave`, an Allure formatter for behave. html :pypi:`behave-html-formatter`, a simple HTML formatter for behave. teamcity :pypi:`behave-teamcity`, a formatter for JetBrains TeamCity CI testruns with behave. ============== ========================================================================= The usage of a custom formatter can be simplified if a formatter alias is defined for.",,"EXAMPLE: .. code-block:: ini # -- FILE: behave.ini # FORMATTER ALIASES: behave -f allure and others... [behave.formatters] allure = allure_behave.formatter:AllureFormatter html = behave_html_formatter:HTMLFormatter teamcity = behave_teamcity:TeamcityFormatter Embedding Screenshots / Data in Reports ------------------------------------------------------------------------------ :Hint 1: Only supported by JSON formatter :Hint 2: Binary attachments may require base64 encoding. You can embed data in reports with the :class:`~behave.runner.Context` method :func:`~behave.runner.Context.attach()`, if you have configured a formatter that supports it. Currently only the JSON formatter supports embedding data. For example: .. code-block:: python # -- FILE: features/steps/screenshot_example_steps.py from behave import given, when from behave4example.web_browser.util import take_screenshot_and_attach_to_scenario @given(u'I open the Google webpage') @when(u'I open the Google webpage') def step_open_google_webpage(ctx): ctx.browser.get(https://www.google.com) take_screenshot_and_attach_to_scenario(ctx) .. code-block:: python # -- FILE: behave4example/web_browser/util.py # HINTS: # * EXAMPLE CODE ONLY # * BROWSER-SPECIFIC: Implementation may depend on browser driver. def take_screenshot_and_attach_to_scenario(ctx): # -- HINT: SELENIUM WITH CHROME: ctx.browser.get_screenshot_as_base64() screenshot_image = ctx.browser.get_full_page_screenshot_as_png() ctx.attach(image/png, screenshot_image) .. code-block:: python # -- FILE: features/environment.py # EXAMPLE REQUIRES: This browser driver setup code (or something similar). from selenium import webdriver def before_all(ctx): ctx.browser = webdriver.Firefox()",Feature23.feature,Validate JSON output from features/ test run,I use the current directory as working directory,, it should pass with validate: testrun1.json ... OK 
Record24.rst,.. _id.appendix.formatters: ======================== Formatters and Reporters ======================== :pypi:`behave` provides 2 different concepts for reporting results of a test run: * formatters * reporters A slightly different interface is provided for each formatter concept. The ``Formatter`` is informed about each step that is taken. The ``Reporter`` has a more coarse-grained API. Reporters --------- The following reporters are currently supported: ============== ================================================================ Name Description ============== ================================================================ junit Provides JUnit XML-like output. summary Provides a summary of the test run. ============== ================================================================ Formatters ---------- The following formatters are currently supported: ============== ======== ================================================================ Name Mode Description ============== ======== ================================================================ help normal Shows all registered formatters. bad_steps dry-run Shows BAD STEP-DEFINITIONS (if any exist). json normal JSON dump of test run json.pretty normal JSON dump of test run (human readable) plain normal Very basic formatter with maximum compatibility pretty normal Standard colourised pretty formatter progress normal Shows dotted progress for each executed scenario. progress2 normal Shows dotted progress for each executed step. progress3 normal Shows detailed progress for each step of a scenario. rerun normal Emits scenario file locations of failing scenarios sphinx.steps dry-run Generate sphinx-based documentation for step definitions. steps dry-run Shows step definitions (step implementations). steps.catalog dry-run Shows non-technical documentation for step definitions. steps.code dry-run Shows executed steps combined with their code. steps.doc dry-run Shows documentation for step definitions. steps.usage dry-run Shows how step definitions are used by steps (in feature files). tags dry-run Shows tags (and how often they are used). tags.location dry-run Shows tags and the location where they are used. ============== ======== ================================================================ .. note:: You can use more than one formatter during a test run. But in general you have only one formatter that writes to ``stdout``. The Mode column indicates if a formatter is intended to be used in dry-run (``--dry-run`` command-line option) or normal mode.,"User-Defined Formatters ----------------------- Behave allows you to provide your own formatter (class):: # -- USE: Formatter class Json2Formatter in python module foo.bar # NOTE: Formatter must be importable from python search path. behave -f foo.bar:Json2Formatter ... The usage of a user-defined formatter can be simplified by providing an alias name for it in the configuration file: .. code-block:: ini # -- FILE: behave.ini # ALIAS SUPPORTS: behave -f json2 ... # NOTE: Formatter aliases may override builtin formatters. [behave.formatters] json2 = foo.bar:Json2Formatter If your formatter can be configured, you should use the userdata concept to provide them. The formatter should use the attribute schema: .. code-block:: ini # -- FILE: behave.ini # SCHEMA: behave.formatter.<FORMATTER_NAME>.<ATTRIBUTE_NAME> [behave.userdata] behave.formatter.json2.use_pretty = true # -- SUPPORTS ALSO: # behave -f json2 -D behave.formatter.json2.use_pretty ... More Formatters --------------- The following contributed formatters are currently known: ============== ========================================================================= Name Description ============== ========================================================================= allure :pypi:`allure-behave`, an Allure formatter for behave. html :pypi:`behave-html-formatter`, a simple HTML formatter for behave. teamcity :pypi:`behave-teamcity`, a formatter for JetBrains TeamCity CI testruns with behave. ============== ========================================================================= The usage of a custom formatter can be simplified if a formatter alias is defined for.",,"EXAMPLE: .. code-block:: ini # -- FILE: behave.ini # FORMATTER ALIASES: behave -f allure and others... [behave.formatters] allure = allure_behave.formatter:AllureFormatter html = behave_html_formatter:HTMLFormatter teamcity = behave_teamcity:TeamcityFormatter Embedding Screenshots / Data in Reports ------------------------------------------------------------------------------ :Hint 1: Only supported by JSON formatter :Hint 2: Binary attachments may require base64 encoding. You can embed data in reports with the :class:`~behave.runner.Context` method :func:`~behave.runner.Context.attach()`, if you have configured a formatter that supports it. Currently only the JSON formatter supports embedding data. For example: .. code-block:: python # -- FILE: features/steps/screenshot_example_steps.py from behave import given, when from behave4example.web_browser.util import take_screenshot_and_attach_to_scenario @given(u'I open the Google webpage') @when(u'I open the Google webpage') def step_open_google_webpage(ctx): ctx.browser.get(https://www.google.com) take_screenshot_and_attach_to_scenario(ctx) .. code-block:: python # -- FILE: behave4example/web_browser/util.py # HINTS: # * EXAMPLE CODE ONLY # * BROWSER-SPECIFIC: Implementation may depend on browser driver. def take_screenshot_and_attach_to_scenario(ctx): # -- HINT: SELENIUM WITH CHROME: ctx.browser.get_screenshot_as_base64() screenshot_image = ctx.browser.get_full_page_screenshot_as_png() ctx.attach(image/png, screenshot_image) .. code-block:: python # -- FILE: features/environment.py # EXAMPLE REQUIRES: This browser driver setup code (or something similar). from selenium import webdriver def before_all(ctx): ctx.browser = webdriver.Firefox()",Feature24.feature,Validate JSON output from issue.features/ test run,I use the current directory as working directory,,it should pass with  validate: testrun2.json ... OK
Record25.rst,.. _id.appendix.formatters: ======================== Formatters and Reporters ======================== :pypi:`behave` provides 2 different concepts for reporting results of a test run: * formatters * reporters A slightly different interface is provided for each formatter concept. The ``Formatter`` is informed about each step that is taken. The ``Reporter`` has a more coarse-grained API. Reporters --------- The following reporters are currently supported: ============== ================================================================ Name Description ============== ================================================================ junit Provides JUnit XML-like output. summary Provides a summary of the test run. ============== ================================================================ Formatters ---------- The following formatters are currently supported: ============== ======== ================================================================ Name Mode Description ============== ======== ================================================================ help normal Shows all registered formatters. bad_steps dry-run Shows BAD STEP-DEFINITIONS (if any exist). json normal JSON dump of test run json.pretty normal JSON dump of test run (human readable) plain normal Very basic formatter with maximum compatibility pretty normal Standard colourised pretty formatter progress normal Shows dotted progress for each executed scenario. progress2 normal Shows dotted progress for each executed step. progress3 normal Shows detailed progress for each step of a scenario. rerun normal Emits scenario file locations of failing scenarios sphinx.steps dry-run Generate sphinx-based documentation for step definitions. steps dry-run Shows step definitions (step implementations). steps.catalog dry-run Shows non-technical documentation for step definitions. steps.code dry-run Shows executed steps combined with their code. steps.doc dry-run Shows documentation for step definitions. steps.usage dry-run Shows how step definitions are used by steps (in feature files). tags dry-run Shows tags (and how often they are used). tags.location dry-run Shows tags and the location where they are used. ============== ======== ================================================================ .. note:: You can use more than one formatter during a test run. But in general you have only one formatter that writes to ``stdout``. The Mode column indicates if a formatter is intended to be used in dry-run (``--dry-run`` command-line option) or normal mode.,"User-Defined Formatters ----------------------- Behave allows you to provide your own formatter (class):: # -- USE: Formatter class Json2Formatter in python module foo.bar # NOTE: Formatter must be importable from python search path. behave -f foo.bar:Json2Formatter ... The usage of a user-defined formatter can be simplified by providing an alias name for it in the configuration file: .. code-block:: ini # -- FILE: behave.ini # ALIAS SUPPORTS: behave -f json2 ... # NOTE: Formatter aliases may override builtin formatters. [behave.formatters] json2 = foo.bar:Json2Formatter If your formatter can be configured, you should use the userdata concept to provide them. The formatter should use the attribute schema: .. code-block:: ini # -- FILE: behave.ini # SCHEMA: behave.formatter.<FORMATTER_NAME>.<ATTRIBUTE_NAME> [behave.userdata] behave.formatter.json2.use_pretty = true # -- SUPPORTS ALSO: # behave -f json2 -D behave.formatter.json2.use_pretty ... More Formatters --------------- The following contributed formatters are currently known: ============== ========================================================================= Name Description ============== ========================================================================= allure :pypi:`allure-behave`, an Allure formatter for behave. html :pypi:`behave-html-formatter`, a simple HTML formatter for behave. teamcity :pypi:`behave-teamcity`, a formatter for JetBrains TeamCity CI testruns with behave. ============== ========================================================================= The usage of a custom formatter can be simplified if a formatter alias is defined for.",,"EXAMPLE: .. code-block:: ini # -- FILE: behave.ini # FORMATTER ALIASES: behave -f allure and others... [behave.formatters] allure = allure_behave.formatter:AllureFormatter html = behave_html_formatter:HTMLFormatter teamcity = behave_teamcity:TeamcityFormatter Embedding Screenshots / Data in Reports ------------------------------------------------------------------------------ :Hint 1: Only supported by JSON formatter :Hint 2: Binary attachments may require base64 encoding. You can embed data in reports with the :class:`~behave.runner.Context` method :func:`~behave.runner.Context.attach()`, if you have configured a formatter that supports it. Currently only the JSON formatter supports embedding data. For example: .. code-block:: python # -- FILE: features/steps/screenshot_example_steps.py from behave import given, when from behave4example.web_browser.util import take_screenshot_and_attach_to_scenario @given(u'I open the Google webpage') @when(u'I open the Google webpage') def step_open_google_webpage(ctx): ctx.browser.get(https://www.google.com) take_screenshot_and_attach_to_scenario(ctx) .. code-block:: python # -- FILE: behave4example/web_browser/util.py # HINTS: # * EXAMPLE CODE ONLY # * BROWSER-SPECIFIC: Implementation may depend on browser driver. def take_screenshot_and_attach_to_scenario(ctx): # -- HINT: SELENIUM WITH CHROME: ctx.browser.get_screenshot_as_base64() screenshot_image = ctx.browser.get_full_page_screenshot_as_png() ctx.attach(image/png, screenshot_image) .. code-block:: python # -- FILE: features/environment.py # EXAMPLE REQUIRES: This browser driver setup code (or something similar). from selenium import webdriver def before_all(ctx): ctx.browser = webdriver.Firefox()",Feature25.feature,Validate JSON output from tools/test-features/ test run,I use the current directory as working directory,it should pass with,validate: testrun3.json ... OK
Record26.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record27.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record28.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record29.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record30.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record31.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record32.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record33.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record34.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record35.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record36.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record37.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record38.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record39.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record40.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record41.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record42.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record43.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record44.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record45.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record46.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record47.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record48.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record49.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record50.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record51.txt,Scenario 1,Given 1,And 1,Then 1,file1_out.txt,Out Scenario 1,Out Given 1,Out And 1,Out Then 1
Record52.txt,Scenario 2,Given 2,And 2,Then 2,file2_out.txt,Out Scenario 2,Out Given 2,Out And 2,Out Then 2
Record53.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record54.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record55.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record56.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record57.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record58.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record59.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record60.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record61.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record62.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record63.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record64.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record65.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record66.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record67.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record68.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record69.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record70.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record71.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record72.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record73.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record74.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record75.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record76.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record77.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record78.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record79.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record80.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record81.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record82.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record83.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record84.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record85.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record86.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record87.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record88.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record89.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record90.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record91.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record92.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record93.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record94.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record95.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record96.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record97.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record98.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record99.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
Record100.txt,Scenario 3,Given 3,And 3,Then 3,file3_out.txt,Out Scenario 3,Out Given 3,Out And 3,Out Then 3
